{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af35413e",
   "metadata": {},
   "source": [
    "# QUANAM Technical assessment RAG\n",
    "\n",
    "In this notebook i go trough the steps it took to achieve a successful RAG, using Chromadb, LangChain/Smith/Graph, and an LLM (gpt-4o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876679f",
   "metadata": {},
   "source": [
    "### Initial auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddffcaf4-f468-4efb-b383-b8a2882ad3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4f952",
   "metadata": {},
   "source": [
    "### Definition of initial variables for improved testing and automatization\n",
    "\n",
    "Here i define the variables that we might change in order to test different combinations of RAG's, which include the actual LLM, the amount of documents retrieved for context (k), the name of the new collection based on the embeddings, and amount of examples to send to LangSmith for testing, and an initial basic prompt for testing.\n",
    "\n",
    "The collection name indicates the embeddings selected to embed the documents and create the collection.\n",
    "\n",
    "Four embeddings were selected for testing, two from OpenAI and two from HuggingFace. I couldn't find much information about the differences, other than the size and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f4f2d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "k_value=4\n",
    "k_importance=0 # used for limiting the amount of context taken into account while addressing the distance score of context\n",
    "\n",
    "collection_name = \"OPENAI-small\"\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "examples_amount = 100\n",
    "\n",
    "# Basic RAG Prompt taken from https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=386d8cfe-157b-445e-86e5-42faea85b914\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3dd9b",
   "metadata": {},
   "source": [
    "### Creation of database/collection\n",
    "\n",
    "Based on initial definition of \"collection_name\" i populate or not, the vector database. If no collection exists, a new one is created, using the embeddings selected previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "d5e58c10-9349-4034-8748-33bbdee26b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'OPENAI-small' already exists.\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from uuid import uuid4\n",
    "import json\n",
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from chromadb import PersistentClient\n",
    "\n",
    "# Define collection parameters\n",
    "persist_directory = f\"./chroma_langchain_db/{collection_name}\"\n",
    "\n",
    "# Check if the collection already exists\n",
    "chroma_client = PersistentClient(path=persist_directory)\n",
    "existing_collections = chroma_client.list_collections()\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    ")\n",
    "\n",
    "if collection_name in existing_collections:\n",
    "    print(f\"Collection '{collection_name}' already exists.\")\n",
    "else:\n",
    "    print(f\"Populating new collection '{collection_name}'.\")\n",
    "    with open(\"data/hotpotqa_docs_reduced.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        documents = [Document(page_content=doc['text'], id=idx) for idx, doc in enumerate(json.load(f))]\n",
    "\n",
    "    doc_ids = vector_store.add_documents(documents=documents, ids=[str(uuid4()) for _ in range(len(documents))])\n",
    "    print(len(doc_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75a520",
   "metadata": {},
   "source": [
    "## LangChain Graph for retrieval of information and generation of answers\n",
    "\n",
    "This was achieved following the [LangChain tutorial](https://python.langchain.com/docs/tutorials/rag/)\n",
    "\n",
    "Two functions are added to the sequence, retrieve for context retrieval, and generate for the execution of the previously defined LLM\n",
    "\n",
    "The retrieve function was edited to use the method `similarity_search_with_score` instead of `similarity_search`. This method provides the cosine distance from the question to the context calculated by the vector database. This indicates the similarity between both sentences. We will use this later to evaluate context importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "bfd93f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Here i use similarity_search_with_score instead of similarity_search\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
    "        \n",
    "    return {\"context\": retrieved_docs }\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc, _ in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf868baf",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08362dc",
   "metadata": {},
   "source": [
    "# Local Tests\n",
    "#### In the next sections i will show some issues found while testing:\n",
    "\n",
    "In this case we can see how one of the questions is not very clear, which causes confusion to the model. This indicates that the dataset could have more of these issues, therefore indicating that a 100% success rate might not be feasable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "3ac0f935-b386-4cb6-872c-1763d9c2e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cadmium chloride, which is slightly soluble in alcohol, is also known as CdClâ‚‚.\n",
      "Cadmium chloride is slightly soluble in alcohol.\n"
     ]
    }
   ],
   "source": [
    "# Original question confuses the model:\n",
    "response = graph.invoke({\"question\": \"\"\"Cadmium Chloride is slightly soluble in this chemical, it is also called what?\"\"\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# Slightly edited question yields a correct answer\n",
    "response = graph.invoke({\"question\": \"\"\"Cadmium Chloride is slightly soluble in this chemical, what is it called?\"\"\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8ea38",
   "metadata": {},
   "source": [
    "Test function for simplocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e5ea94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_question, show_context=False):\n",
    "    response = graph.invoke({\"question\": test_question})\n",
    "    print('ANSWER ==================')\n",
    "    print(response[\"answer\"])\n",
    "    if show_context:\n",
    "        print('CONTEXT ==================')\n",
    "        question_context = vector_store.similarity_search_with_score(test_question, k=k_value)\n",
    "        # se invierte el score utilizando '1 - score' porque para calcularlo se utiliza \n",
    "        for context in question_context:\n",
    "            print(f\"{1 - context[1]} * \\n * {context[0].page_content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e67d46",
   "metadata": {},
   "source": [
    "### Usage of LLM previous knowledge \n",
    "\n",
    "There is not enough context to answer this question without using knowledge gathered in the training phase of the LLM. Therefore, we can see how given the initial prompt, the model tends to allucinate, or to fullfill information with his knowledge, answering questions even though its not possible with the given context.\n",
    "\n",
    "(None of the documents in the context relate the actor Steve Landesberg to the documentary \"The Aristocrats\", nor mentions the Emmy awards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "5f069a84-a15d-49cd-b139-e0f9fa999eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER ==================\n",
      "The 2005 documentary \"The Aristocrats\" was dedicated to comedian Steve Landesberg, who was nominated for three Emmy Awards.\n",
      "CONTEXT ==================\n",
      "-0.29104459285736084 * \n",
      " * John Arthur Lithgow ( ; born October 19 , 1945) is an American actor, musician, singer, comedian, voice actor, and author.  He has received two Tony Awards, six Emmy Awards, two Golden Globe Awards, three Screen Actors Guild Awards, an American Comedy Award, four Drama Desk Awards and has also been nominated for two Academy Awards and four Grammy Awards.  Lithgow has received a star on the Hollywood Walk of Fame and has been inducted into the American Theater Hall of Fame.\n",
      "\n",
      "\n",
      "-0.36132943630218506 * \n",
      " * Steve Landesberg (November 23, 1936December 20, 2010) was an American actor, comedian, and voice actor known for his role as the erudite, unflappable police detective Arthur P. Dietrich on the ABC sitcom \"Barney Miller\", for which he was nominated for three Emmy Awards.\n",
      "\n",
      "\n",
      "-0.37810349464416504 * \n",
      " * Geoffrey Roy Rush {'1': \", '2': \", '3': \", '4': \"} (born 6 July 1951) is an Australian actor and film producer.  Rush is the youngest amongst the few people who have won the \"Triple Crown of Acting\": the Academy Award, the Primetime Emmy Award, and the Tony Award.  He has won one Academy Award for acting (from four nominations), three British Academy Film Awards (from five nominations), two Golden Globe Awards and four Screen Actors Guild Awards. Rush is the founding President of the Australian Academy of Cinema and Television Arts and was named the 2012 Australian of the Year.  He is also the first actor to win the Academy Award, BAFTA Award, Critics' Choice Movie Award, Golden Globe Award, and Screen Actors Guild Award for a single performance in film for his performance in \"Shine\" (1996).\n",
      "\n",
      "\n",
      "-0.43809664249420166 * \n",
      " * Swoosie Kurtz ( , ; born September 6, 1944) is an American actress.  She is an Emmy Award winner and two-time Tony Award winner.\n",
      "\n",
      "\n",
      "-0.4526258707046509 * \n",
      " * A Letter to Elia is a 2010 documentary film directed by Kent Jones and Martin Scorsese that follows the life and career of film director Elia Kazan and how he influenced Scorsese.  Made from clips from films, stills, readings from Kazan's autobiography, a speech he wrote on directing read by Elias Koteas, a videotaped interview done late in Kazan's life, and Scorsese's commentary on and off screen.\n",
      "\n",
      "\n",
      "-0.4578855037689209 * \n",
      " * Lost is an American drama series that aired on ABC from September 22, 2004 until May 23, 2010.  It has been nominated for a variety of different awards, including 54 Primetime Emmy Awards (eleven wins), 48 Saturn Awards (thirteen wins), 33 Teen Choice Awards, 17 Television Critics Association Awards (four wins), 12 Golden Reel Awards (five wins), eight Satellite Awards (one win), seven Golden Globe Awards (one win), six Producers Guild of America Awards (one win), six Writers Guild of America Awards (one win), five Directors Guild of America Awards, two NAACP Image Awards (one win), two Screen Actors Guild Awards (one win), and one BAFTA Award.  Amongst the wins for the series are a Primetime Emmy Award for Outstanding Drama Series, a Golden Globe Award for Best Television Series â€“ Drama, a Screen Actors Guild Award for Outstanding Performance by an Ensemble in a Drama Series, and a Peabody Award.\n",
      "\n",
      "\n",
      "-0.45908844470977783 * \n",
      " * Christian Dominique Borle (born October 1, 1973) is an American actor in theatre, television, and film.  He is a two-time Tony Award winner for his roles as Black Stache in \"Peter and the Starcatcher\" and as William Shakespeare in \"Something Rotten! \".  Borle originated the role of Emmett in \"Legally Blonde\" on Broadway , as Tom Levitt on the NBC musical-drama television series \"Smash\" and as Marvin in the 2016 Broadway revival of \"Falsettos\".\n",
      "\n",
      "\n",
      "-0.46529173851013184 * \n",
      " * Paul Edward Haggis (born March 10, 1953) is a Canadian screenwriter, producer, and director of film and television.  He is best known as screenwriter and producer for consecutive Best Picture Oscar winners: \"Million Dollar Baby\" (2004) and \"Crash\" (2005), the latter of which he also directed.  He is the creator of the television series \"Due South\" and the co-creator of \"Walker, Texas Ranger\".  He is a two-time Academy Award winner, two-time Emmy Award winner, and seven-time Gemini Award winner.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"\"\"\n",
    ")\n",
    "\n",
    "test(\"\"\"The 2005 documentary \"The Aristocrats\" was dedicated to a comedian that received how many Emmy Awards?\"\"\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e040e7",
   "metadata": {},
   "source": [
    "#### Same question, different prompt\n",
    "Here we cann see how the same question but a more specific prompt yields a better response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f8d44840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER ==================\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Using only the provided context, answer the following quesitons with\n",
    "    \\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\\n\n",
    "    Keep the answers as shost and concise as possible, and If you dont know the answer, just say that you don't know.\"\"\"\n",
    ")\n",
    "\n",
    "test(\"\"\"The 2005 documentary \"The Aristocrats\" was dedicated to a comedian that received how many Emmy Awards?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67e88c",
   "metadata": {},
   "source": [
    "### Tests conclussions:\n",
    "\n",
    "The way i see it, the idea of a RAG, at least in this case, is to answer questions based exclusively in the context. If we are feeding the model some context about a fictional story of a distant planet, we dont want the model to answer 9.807 m/sÂ² (earth's gravity) when asked about the gravity of the planet in the story. If there is no information about the gravity in the planet, the right answer should be 'i don't know'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33dac8",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9581c05",
   "metadata": {},
   "source": [
    "# Using LangSmith to register the different RAG performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9b59c",
   "metadata": {},
   "source": [
    "I was able to adapt the [evaluate a chatbot](https://docs.smith.langchain.com/evaluation/tutorials/evaluation) tutorial from LangSmith to meet my needs to test the RAG. \n",
    "\n",
    "By defining two evaluators `correctness` and `context` we can check the performance of the RAG for a given question. \n",
    "\n",
    "The `correctness` evaluator uses the LLM as a judge technique to address the correctness of the generated answer, comparing it to the expected answer. Some simple eval instructions are defined for the LLM to evaluate it.\n",
    "\n",
    "The `context` evaluator was added by me, to add the context provided to the 'experiment', along its score, to be able to study the performance in depth from the LangSmith console. This evaluator takes into account the inverse of the distance metric calculated by chromadb using cosine similarity. Higher values indicate higher similarity between a question and a context document.\n",
    "\n",
    "Also, the `k_importance` value is used to determine how many of the `k_value` documents in the context are taken into account to determine the score of the context. This was implemented because there is no dynamic way to retrieve context from the database, its always `k_value`, no matter how similar the document is to the question. This causes problems because if a question can be answered with just one document, this document will have a high score, but since `k_value -1` more documents are in the context, which probably have a really low score, they will lower the overall score average, making this metric unusable.\n",
    "By setting the `k_importance` value to `2` we make sure that the top 2 documents are taken into account to calculate this metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\A'\n",
      "/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py:10: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  return {'key': \"correctness\", 'score': \"INCORRECT\" not in response, 'comment': f\"\"\"Question: \\n {inputs['question']}\\n\\nReference answer: \\n {reference_outputs['answer']}\\n\\nResponse: \\n {outputs['response']}\\n\\n\\n\\Argumentation: \\n {response}\\n\\n\"\"\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define evaluators\n",
    "eval_instructions = \"You are an expert professor specialized in grading students' answers to questions.\"\n",
    "\n",
    "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": eval_instructions},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]).content\n",
    "    return {'key': \"correctness\", 'score': \"INCORRECT\" not in response, 'comment': f\"\"\"Question: \\n {inputs['question']}\\n\\nReference answer: \\n {reference_outputs['answer']}\\n\\nResponse: \\n {outputs['response']}\\n\\n\\n\\Argumentation: \\n {response}\\n\\n\"\"\"} \n",
    "\n",
    "def extract_page_contents(documents):\n",
    "    if not documents:\n",
    "        return \"No documents available.\"\n",
    "\n",
    "    formatted_content = []\n",
    "    for doc, score in documents:\n",
    "        formatted_content.append(f\"--- Document {score} ---\\n{doc.page_content}\\n\")\n",
    "\n",
    "    return \"\\n\".join(formatted_content)\n",
    "\n",
    "def context(outputs: dict) -> dict:\n",
    "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
    "    return {'key': \"context\", 'score': 1 - score_avg, 'comment': extract_page_contents(outputs[\"context\"])}\n",
    "\n",
    "# Run evaluations\n",
    "def ls_target(inputs: str) -> dict:\n",
    "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"response\": response[\"answer\"], \"context\": response[\"context\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c684b01",
   "metadata": {},
   "source": [
    "### LangSmith dataset creation\n",
    "\n",
    "Here i create a questions dataset in LangSmith, if it hasn't been created yet.\n",
    "\n",
    "To do this we use the `examples_amount` value to determine how many questions of the questions dataset we want to randomly select for this test suite.\n",
    "\n",
    "With this dataset we make sure to use the same questions to evaluate different RAG configurations,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "60439603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Random 500 already created\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "import random\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = f\"Random {examples_amount}\"\n",
    "\n",
    "datasets = client.list_datasets()\n",
    "dataset_id = next((d.id for d in datasets if d.name == dataset_name), None)\n",
    "\n",
    "if not dataset_id:\n",
    "    print('Creating new questions dataset')\n",
    "    dataset = client.create_dataset(dataset_name)\n",
    "    dataset_id = dataset.id\n",
    "\n",
    "    with open(\"data/hotpotqa_docs_reduced_qa.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    samples = random.sample(data, examples_amount)\n",
    "    \n",
    "    selected_questions = [{\"question\": item[\"question\"]} for item in samples]\n",
    "    selected_answers = [{\"answer\": item[\"answer\"]} for item in samples]\n",
    "    \n",
    "    client.create_examples(\n",
    "        inputs=selected_questions,\n",
    "        outputs=selected_answers,\n",
    "        dataset_id=dataset_id,\n",
    "    )\n",
    "else:\n",
    "    print(f'Dataset {dataset_name} already created')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb8168",
   "metadata": {},
   "source": [
    "## LangSmith tests setups\n",
    "\n",
    "In this section i define three basic tests, in which i use a different prompt for each one.\n",
    "\n",
    "Each test was executed for each one of the 4 embeddings selected, being the experiment_prefix a combination of the collection_name and the prompt description.\n",
    "\n",
    "For comparing these tests, a small sample of 100 random questions was taken, and the same 100 questions were asked with each of the 3 prompts, to each embedding collection.\n",
    "\n",
    "In [this LangSmith link](https://smith.langchain.com/public/6db8dd34-cf63-4721-a8b1-05ae9d521e33/d) you can see the different results yielded by the combinations. The results are also addressed in the documents provided in the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc120c",
   "metadata": {},
   "source": [
    "This is the base benchmark test, i use the default prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f9540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'OPENAI_large_k8_base-prompt-b60ddafd' at:\n",
      "https://smith.langchain.com/o/386d8cfe-157b-445e-86e5-42faea85b914/datasets/1cf2bce7-e4e6-45d1-9f99-d680de2cde59/compare?selectedSessions=dfe74b7b-a1e2-4861-9220-fa06a6862526\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "434it [26:58,  4.93s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '31ab8e47-ad3d-ab98-dfaa-5947c6b79c1c'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 793934c5-3391-4b14-9855-0a67fb08c062: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 793934c5-3391-4b14-9855-0a67fb08c062: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "435it [27:01,  4.20s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '426d4436-5581-fc5d-0008-7ff31d85685b'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 988f7c19-a216-4955-8632-fab8e60c686d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 988f7c19-a216-4955-8632-fab8e60c686d: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "436it [27:03,  3.55s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'bfc9636c-12dd-3628-b4e4-d04d32575b51'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run e90278bb-e3f1-45a0-9947-64454cfa715d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run e90278bb-e3f1-45a0-9947-64454cfa715d: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "437it [27:05,  3.09s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'bf44bd9f-2201-8f1e-8a8f-11645b0410c8'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run acf80983-f225-4de3-8138-18fa7b51d66c: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run acf80983-f225-4de3-8138-18fa7b51d66c: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "438it [27:07,  2.79s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'bd841297-7606-9de7-b139-9522bd8abb7d'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run b566bd8c-d87b-4cf9-9a18-a650f96875c3: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run b566bd8c-d87b-4cf9-9a18-a650f96875c3: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "439it [27:09,  2.58s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'dda201f1-57bf-ea39-434b-522c5726156c'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 6614800d-4e80-4b96-a4e7-27157b6ad30c: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 6614800d-4e80-4b96-a4e7-27157b6ad30c: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "440it [27:11,  2.45s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '0cd060d4-7def-fc11-e148-a1474f175756'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 9dd3d3e8-0534-4bff-b4d8-38e61a294200: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 9dd3d3e8-0534-4bff-b4d8-38e61a294200: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "441it [27:13,  2.36s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '79cb6683-1c44-a165-b64f-2c1e989811e2'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run c3602a49-e6c5-4833-8a31-070a68a20f6d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run c3602a49-e6c5-4833-8a31-070a68a20f6d: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "442it [27:15,  2.25s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '306c27a9-a55e-98d7-161e-d8305cb49f43'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run f9d92880-493f-45e5-a51f-460f3bd62be0: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run f9d92880-493f-45e5-a51f-460f3bd62be0: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "443it [27:18,  2.33s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '5a0ee4ea-3552-7f6c-581f-4e54067b12cf'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 4bfba070-04c0-48a1-b7ab-6e32d4a12e4f: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 4bfba070-04c0-48a1-b7ab-6e32d4a12e4f: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "444it [27:20,  2.42s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'fb367254-eec9-e291-f1d1-a5d4ecd2d123'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 474baef2-1246-4089-a026-e58f5d0c664a: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 474baef2-1246-4089-a026-e58f5d0c664a: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "445it [27:23,  2.32s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '10976e72-c7db-689e-b1b6-b60b5ade949e'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run fd1aea02-2be8-4971-9bd9-1badf2aaf5c2: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run fd1aea02-2be8-4971-9bd9-1badf2aaf5c2: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "446it [27:25,  2.23s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '7b0dd452-fac5-ad0a-05bd-be4c23e8bacf'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 6156d4bd-2280-4dfb-9a60-81854c2ade81: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 6156d4bd-2280-4dfb-9a60-81854c2ade81: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "447it [27:27,  2.17s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'a733c36d-ec0f-91f9-a321-5d74c6fecf08'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run c3a65ea7-9694-4585-b988-e1b2355c7770: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run c3a65ea7-9694-4585-b988-e1b2355c7770: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "448it [27:29,  2.15s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '54e447ae-19f4-5cb9-a883-7ec81427a5ac'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 796bbcd8-a782-4acd-bfd6-584009afb2b6: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 796bbcd8-a782-4acd-bfd6-584009afb2b6: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "449it [27:31,  2.15s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'e4bf085a-53a8-ca9a-f587-8eb6161c694c'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 7df11bd0-383e-4b68-9522-6f6728eef441: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 7df11bd0-383e-4b68-9522-6f6728eef441: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "450it [27:33,  2.14s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'd1544fd8-1d8b-d059-b843-9f54c834be60'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run f8c47bb2-4eea-412e-89dc-88f5d4f15a76: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run f8c47bb2-4eea-412e-89dc-88f5d4f15a76: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "451it [27:35,  2.14s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '99f9da3c-a736-d33e-0986-fd80b343ed8b'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run bb695528-f73d-4cce-83fe-1c9a12d65859: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run bb695528-f73d-4cce-83fe-1c9a12d65859: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "452it [27:37,  2.10s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '52b92882-e248-b1ae-dd0b-f98f14b17cfb'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 1e7d59eb-f4ae-42b9-8552-2e63afbf803d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 1e7d59eb-f4ae-42b9-8552-2e63afbf803d: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "453it [27:39,  2.08s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '9c2724c7-ac06-1d89-d9e7-a721acbad920'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run ce51503d-6be9-4206-974b-b5ad3f83cac3: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run ce51503d-6be9-4206-974b-b5ad3f83cac3: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "454it [27:41,  2.08s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'e4713ba8-f494-5003-2be3-c103e2447f12'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 58bdbe8d-2df0-4893-afd2-7193ded274ad: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 58bdbe8d-2df0-4893-afd2-7193ded274ad: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "455it [27:43,  2.05s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '5b209d76-9dea-44fa-a264-f46d0de577e2'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 1a2f6284-671d-45f9-9d3f-83a3d94376fc: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 1a2f6284-671d-45f9-9d3f-83a3d94376fc: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "456it [27:45,  2.02s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'da342972-96d1-f2b3-4462-77a3d26f4ad5'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 1dbb8303-bede-4bbe-8ca9-5a3f4159d0e6: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 1dbb8303-bede-4bbe-8ca9-5a3f4159d0e6: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "457it [27:47,  1.98s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'fe632cdf-350f-c0cb-1b6d-9f7ce53b30f9'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 81b9959f-e190-4bb7-ba62-15bf101973c2: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 81b9959f-e190-4bb7-ba62-15bf101973c2: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "458it [27:49,  2.04s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'ebecd013-e970-967b-5178-80f2bc921b98'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 7b0c19a9-9972-41f9-9d02-e2584766b4b3: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 7b0c19a9-9972-41f9-9d02-e2584766b4b3: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "459it [27:51,  2.01s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'd8f089bf-09e7-69e1-30ae-92274ae9e09f'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run ede176d7-bdd0-4d07-8a25-f149a5851676: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run ede176d7-bdd0-4d07-8a25-f149a5851676: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "460it [27:53,  2.02s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '09f749ec-5e22-5a3a-32d9-72d03f8c78f2'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run d4206265-5eeb-4673-8132-d3594a1a39db: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run d4206265-5eeb-4673-8132-d3594a1a39db: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "461it [27:55,  2.06s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '6ccfa362-333b-5561-f298-1d564b58736f'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 2e253f05-f494-4a76-87a3-fe9c95d3f104: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 2e253f05-f494-4a76-87a3-fe9c95d3f104: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "462it [27:57,  2.05s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'b19c908f-4904-aa1c-1ff2-a58b4dcb8c0e'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 2301cdd6-b266-4bc2-94bc-3030d936a5c9: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 2301cdd6-b266-4bc2-94bc-3030d936a5c9: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "463it [28:00,  2.09s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'ab3422db-7bb2-aee8-1da6-563c28b67f3d'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 1d5e1dc6-c0a4-4510-95e7-af714c1d078e: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 1d5e1dc6-c0a4-4510-95e7-af714c1d078e: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "464it [28:02,  2.06s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '7e487fd9-445b-14f3-555f-29900f0536e0'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 29bf3ce5-f29e-4449-b6d8-aafe8b370a50: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 29bf3ce5-f29e-4449-b6d8-aafe8b370a50: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "465it [28:04,  2.13s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'f1acdd3a-9d74-1b9d-9ea2-5d40bc4ceed5'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run e7c4ef9d-48b0-4f85-aed0-31f82c436b7a: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run e7c4ef9d-48b0-4f85-aed0-31f82c436b7a: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "466it [28:06,  2.11s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '4f2372b3-4631-9d1f-dc5c-60844356810f'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run a816fcd8-ec26-4f6b-968f-db93e8acd255: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run a816fcd8-ec26-4f6b-968f-db93e8acd255: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "467it [28:08,  2.07s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '9be18a99-29cf-364d-085b-ae63ab2bda8e'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 61ce8a63-4ec8-48bf-ad03-d931f77f00a5: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 61ce8a63-4ec8-48bf-ad03-d931f77f00a5: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "468it [28:10,  2.02s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'c80b88fa-531c-cf7e-128c-b5817d998bed'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 99c2b561-e5ae-4c45-b693-cd922cff108f: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 99c2b561-e5ae-4c45-b693-cd922cff108f: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "469it [28:12,  2.05s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'bbff2a1e-0963-907f-4599-f0125a48178f'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 46dbcc05-2c41-4075-b515-fe05007b2f24: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 46dbcc05-2c41-4075-b515-fe05007b2f24: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "470it [28:14,  2.07s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '161acccd-f43a-3774-be1c-1cd7722fd636'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 6a5ff26d-6c19-4b4a-be32-687ba9b6e982: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 6a5ff26d-6c19-4b4a-be32-687ba9b6e982: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "471it [28:16,  2.03s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '753541d4-9b23-a9b7-4603-90afc27a6b5b'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run faf4e907-bc1d-4530-87ed-bb790fd8f8b1: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run faf4e907-bc1d-4530-87ed-bb790fd8f8b1: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "472it [28:18,  2.06s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'c746d967-a32d-2ca9-f3cc-3e55a7946aad'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 0e82d898-ed1d-48bc-9a0b-01af2d92c91d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 0e82d898-ed1d-48bc-9a0b-01af2d92c91d: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "473it [28:20,  2.01s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '8b4cc108-679c-51cc-5efd-d5cf7dbe893e'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 4c31b04c-51a1-454f-8199-62b08f73c0ef: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 4c31b04c-51a1-454f-8199-62b08f73c0ef: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "474it [28:22,  2.04s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '443e2e35-4536-7f39-eb68-7ea638317f6d'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run ed061951-110a-4799-a0e1-a68fed996455: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run ed061951-110a-4799-a0e1-a68fed996455: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "475it [28:24,  2.07s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '5f491b3b-46b3-83e8-833f-37c2d769b2b0'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 549d427c-e69b-4ed5-b3e6-689f15a4b2fa: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 549d427c-e69b-4ed5-b3e6-689f15a4b2fa: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "476it [28:26,  2.10s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '94d90b6d-5926-6d81-daf9-c62d0884f6dc'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 5e17e2c6-ca11-4011-a2f6-69ee4009cc0b: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 5e17e2c6-ca11-4011-a2f6-69ee4009cc0b: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "477it [28:29,  2.11s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'af1a8ac8-27ba-806f-f25e-6acc05618ce5'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run f35cfd41-a7ed-4cc3-ba01-33fa838380a6: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run f35cfd41-a7ed-4cc3-ba01-33fa838380a6: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "478it [28:31,  2.09s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '1bc5ce62-61d0-8c63-0670-654327e21cd8'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run ce9bee71-1ebd-491c-a426-d9fa9b003448: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run ce9bee71-1ebd-491c-a426-d9fa9b003448: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "479it [28:33,  2.08s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'f38eacb9-5bd5-c602-caa2-968318923e4c'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 7eb487e6-1815-4a13-923f-9bd466b8ebce: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 7eb487e6-1815-4a13-923f-9bd466b8ebce: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "480it [28:35,  2.03s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'b59e0f12-8f96-250e-2e1d-2626b0391e9f'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 2b7607a3-e51d-4079-9999-18472a138296: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 2b7607a3-e51d-4079-9999-18472a138296: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "481it [28:37,  2.02s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '0a0e27ee-3449-3f36-0c47-44aa32a9d5b8'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 7b5e8dc3-ac8f-4c1e-9b11-a18056b013a3: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 7b5e8dc3-ac8f-4c1e-9b11-a18056b013a3: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "482it [28:39,  2.06s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '18ef9bbf-0fc5-a2a1-8f22-c3fda737c30a'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 1b4a578c-f2cf-4e73-ba29-5cd1981fcdc1: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 1b4a578c-f2cf-4e73-ba29-5cd1981fcdc1: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "483it [28:41,  2.04s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'eb3a830a-1a0e-3c6a-d528-96709444680a'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run dc1441af-4619-45a1-a705-8dd9c5e332ac: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run dc1441af-4619-45a1-a705-8dd9c5e332ac: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "484it [28:43,  2.04s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'fd8bcc23-4341-60bf-0442-1d65b8a59e81'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run cfa65e45-6304-4a92-9d90-f821440321fb: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run cfa65e45-6304-4a92-9d90-f821440321fb: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "485it [28:45,  2.02s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'ec391294-dd04-af4e-97f1-5d7c1d54084d'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run df4138fe-9a90-4c64-a852-a8b7f751c345: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run df4138fe-9a90-4c64-a852-a8b7f751c345: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "486it [28:47,  2.03s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '94522abb-cefc-ff69-dc30-09b9ac4f537a'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 6e624fc2-44f1-437a-abf8-fc0bc1e4d0a4: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 6e624fc2-44f1-437a-abf8-fc0bc1e4d0a4: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "487it [28:49,  2.03s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '9bf3df1d-c26e-ab44-53fe-2c70d27fd277'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 34b2d269-7df6-45ec-b28b-1bb473a149f9: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 34b2d269-7df6-45ec-b28b-1bb473a149f9: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "488it [28:51,  2.02s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'abbe3024-c7e7-3266-2249-9e4497b03ffd'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 0ff5e531-f9f3-4d7b-8279-3706dc914957: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 0ff5e531-f9f3-4d7b-8279-3706dc914957: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "489it [28:53,  1.97s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '74d31d9f-b98c-0b15-4782-d36036373183'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 658fd432-7875-4787-bc22-eefa4afa9901: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 658fd432-7875-4787-bc22-eefa4afa9901: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "490it [28:55,  2.10s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '74fbef88-1da1-ab3b-845a-423ebda345c6'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run e6b4a265-2e65-463f-9b47-f008f6533b7d: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run e6b4a265-2e65-463f-9b47-f008f6533b7d: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "491it [28:57,  2.07s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '382bc965-b22f-f88b-26ed-a0852cb157e1'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 58c84b8e-5d1e-4fd0-ad5b-c348e1c6327a: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 58c84b8e-5d1e-4fd0-ad5b-c348e1c6327a: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "492it [28:59,  2.05s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '1006c328-0948-5ffe-00cd-bc51f26e072a'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run f3f4d8a1-1aa0-4eeb-8d37-06425dc5fca1: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run f3f4d8a1-1aa0-4eeb-8d37-06425dc5fca1: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "493it [29:01,  2.06s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '32844b65-11a7-d224-289c-99c06eda08a6'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 68733500-3ef3-4905-b2ae-6f014a69267a: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 68733500-3ef3-4905-b2ae-6f014a69267a: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "494it [29:03,  2.04s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '2a51cf44-21f0-1b79-607a-23e230cd7a68'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 7ac2318b-98ea-4943-a38a-87277a71b622: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 7ac2318b-98ea-4943-a38a-87277a71b622: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "495it [29:05,  2.03s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '3dc98700-4da8-21b0-9c76-87060ea04b0a'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 191565a5-9f83-4c10-9fa1-33bceea573ff: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 191565a5-9f83-4c10-9fa1-33bceea573ff: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "496it [29:07,  2.02s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '344c4424-326a-ed2a-add4-4e3e00c0d15e'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run ff067709-02c1-4c15-9017-4d231f8d4729: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run ff067709-02c1-4c15-9017-4d231f8d4729: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "497it [29:09,  2.03s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id 'b132c77e-6384-90bc-72b5-30134c91cd7e'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 49755a52-01a5-428a-bd13-26f2a1bfde53: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 49755a52-01a5-428a-bd13-26f2a1bfde53: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "498it [29:11,  2.08s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '4f9b92a9-291d-bc0f-2a3f-92f4fed0f59b'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 06f8e6f1-8cce-4b50-9ce8-bb7531745fba: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 06f8e6f1-8cce-4b50-9ce8-bb7531745fba: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "499it [29:13,  2.07s/it]Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 28, in ls_target\n",
      "    response = graph.invoke({\"question\": inputs[\"question\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2124, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 1779, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/3487602724.py\", line 14, in retrieve\n",
      "    retrieved_docs = vector_store.similarity_search_with_score(state[\"question\"], k=k_value)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_chroma/vectorstores.py\", line 705, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 629, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 588, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langchain_openai/embeddings/base.py\", line 483, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/resources/embeddings.py\", line 128, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1290, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 967, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1056, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1105, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/openai/_base_client.py\", line 1071, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "During task with name 'retrieve' and id '53b2dcd9-7956-eb89-b18b-f9e5e18de488'\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 1c04e308-81cc-485d-bc1f-aa91f340c362: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 5, in correctness\n",
      "    user_content = f\"\"\"You are grading the following question:{inputs['question']} Here is the real answer: {reference_outputs['answer']} You are grading the following predicted answer: {outputs['response']} Start the message with CORRECT or INCORRECT, and then provide argumentation for your decision\"\"\"\n",
      "                                                                                                                                                                                           ~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running evaluator <DynamicRunEvaluator context> on run 1c04e308-81cc-485d-bc1f-aa91f340c362: KeyError('context')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 629, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/run_helpers.py\", line 626, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Nico/repos/quanam/quanam/lib/python3.12/site-packages/langsmith/evaluation/evaluator.py\", line 723, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/gr/ntznzvt96xv2_6vsz3rt8lxh0000gp/T/ipykernel_69628/929511936.py\", line 23, in context\n",
      "    score_avg = sum(score for _, score in outputs[\"context\"][:k_value-k_importance]) / len(outputs[\"context\"][:k_value-k_importance])\n",
      "                                          ~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'context'\n",
      "500it [29:16,  3.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ExperimentResults OPENAI_large_k8_base-prompt-b60ddafd>"
      ],
      "text/plain": [
       "<ExperimentResults OPENAI_large_k8_base-prompt-b60ddafd>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST 1 ==========================\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"\"\"\n",
    ")\n",
    "\n",
    "client.evaluate(\n",
    "    ls_target, \n",
    "    data=dataset_name,  \n",
    "    evaluators=[correctness, context],  \n",
    "    experiment_prefix=f\"{collection_name}_base-prompt\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d2082",
   "metadata": {},
   "source": [
    "This tests tries to avoid using any other data than the one in the context by using 'ONLY' to be more explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b027aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'HF-mpnet-base-v2_k8_base-prompt-with-(ONLY)-ff862a20' at:\n",
      "https://smith.langchain.com/o/386d8cfe-157b-445e-86e5-42faea85b914/datasets/1cf2bce7-e4e6-45d1-9f99-d680de2cde59/compare?selectedSessions=963dcc49-f3b6-47d3-8d40-041f1021e96e\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [27:39,  3.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ExperimentResults HF-mpnet-base-v2_k8_base-prompt-with-(ONLY)-ff862a20>"
      ],
      "text/plain": [
       "<ExperimentResults HF-mpnet-base-v2_k8_base-prompt-with-(ONLY)-ff862a20>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST 2 ==========================\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use ONLY the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"\"\"\n",
    ")\n",
    "\n",
    "client.evaluate(\n",
    "    ls_target, \n",
    "    data=dataset_name, \n",
    "    evaluators=[correctness, context], \n",
    "    experiment_prefix=f\"{collection_name}_base-prompt-with-(ONLY)\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa466dc",
   "metadata": {},
   "source": [
    "This this is a similar prompt, but a bit different and concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "74f443fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'HF-MiniLM-L6-v2_custom-prompt-57ca54c4' at:\n",
      "https://smith.langchain.com/o/386d8cfe-157b-445e-86e5-42faea85b914/datasets/e6f93c89-bde6-45bb-b350-19e959d857fb/compare?selectedSessions=75bf055f-dc98-421f-be29-b14f95debe21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [04:59,  2.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ExperimentResults HF-MiniLM-L6-v2_custom-prompt-57ca54c4>"
      ],
      "text/plain": [
       "<ExperimentResults HF-MiniLM-L6-v2_custom-prompt-57ca54c4>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST 3 ==========================\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Using only the provided context, answer the following quesitons with\n",
    "    \\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\\n\n",
    "    Keep the answers as shost and concise as possible, and If you dont know the answer, just say that you don't know.\"\"\"\n",
    ")\n",
    "\n",
    "client.evaluate(\n",
    "    ls_target, \n",
    "    data=dataset_name,  \n",
    "    evaluators=[correctness, context], \n",
    "    experiment_prefix=f\"{collection_name}_custom-prompt\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b970eb",
   "metadata": {},
   "source": [
    "This was meant to test other LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "43307feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST 4 ==========================\n",
    "\n",
    "# llm = ChatOpenAI(model=\"o1\")\n",
    "\n",
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"\"\"You are an assistant for question-answering tasks. \n",
    "#     Use the following pieces of retrieved context to answer the question. \n",
    "#     If you don't know the answer, just say that you don't know. \n",
    "#     Use three sentences maximum and keep the answer concise.\n",
    "#     \\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"\"\"\n",
    "# )\n",
    "\n",
    "# client.evaluate(\n",
    "#     ls_target,\n",
    "#     data=dataset_name,\n",
    "#     evaluators=[correctness, context], \n",
    "#     experiment_prefix=\"o1_base-prompt\", \n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quanam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
